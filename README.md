## SpOOx - Spatial Omics Oxford Analysis Pipeline
This pipeline has automated the analysis of mcd image files (generated by the [Fluidigm Hyperion Imaging System](https://www.fluidigm.com/products-services/instruments/hyperion)) using [imctools](https://github.com/BodenmillerGroup/imctools) and [DeepCell](https://simtk.org/projects/deepcell) for image processing and segmentation, and custom python and R scripts to extract image intensities for a variety of cell markers. The image intensities can be further analysed using [MLV - Multi-locus View](https://www.nature.com/articles/s42003-021-02097-y), and the associated images can be analysed using [Zegami](https://zegami.com/). The pipeline itself has been written using the python pipelining tool, [Ruffus](http://www.ruffus.org.uk).

### Set-up the pipeline ##################
Note: assuming conda has been installed and in the system path
```
git clone https://github.com/bioinfbloke/SpOOx.git
```

```
conda activate base
conda env create -n hyperion -f </path/to/>hyperion.yml
conda activate hyperion
```

### Run the pipeline ##################

Config:
```
cd <your_working_dir>

cp pipeline.yml .
# edit pipeline.yml params (eg, cluster queue name;  zegami options)
```

Input data - create a 'mcd' dir to contain all the .mcd data files to be analysed:
```
mkdir mcd 
```
Copy (or symlink) .mcd files to mcd/ dir. 

Each .mcd file should be in its own, named dir within the mcd dir. The file and dir names are constructed using three elements (\<sampleName\>, "sample", \<sampleId\>) separated by underscores. For example:
```
<your working dir>/mcd/AB_sample_1/AB_sample_1.mcd
<your working dir>/mcd/AB_sample_2/AB_sample_2.mcd
<your working dir>/mcd/CD_sample_1/CD_sample_1.mcd
<your working dir>/mcd/CD_sample_2/CD_sample_2.mcd
<your working dir>/mcd/CD_sample_3/CD_sample_3.mcd
<your working dir>/mcd/EF_sample_1/EF_sample_1.mcd
```

### Pipeline commands:
A basic Ruffus function 'show' can be used to describe the steps that make up the pipeline:
```
python hyperion_pipeline.py show
```
====================================

[imctools](https://github.com/BodenmillerGroup/imctools) works on folders not files, but folders are poor for tracking within a pipeline as their modicfication time is updated on access. To mitigate this we use a hidden dummy file (.ruffus) which is added to each directory of interest in the mcd dir for tracking purposes.

```
python hyperion_pipeline.py mark_input_folders
```
====================================
```
python hyperion_pipeline.py make mcd_to_tiff
```
====================================
```
python hyperion_pipeline.py make tiff_to_histocat
```
====================================
```
python hyperion_pipeline.py make make_config
```
Note - the config SHOULD be edited at this point before proceding to the next step

====================================
```
python hyperion_pipeline.py make deepcell
```
====================================
```
python hyperion_pipeline.py make signal_extraction
```
====================================

Optional step for visualisation using Zegami (account required: https://zegami.com/)
```
python hyperion_pipeline.py make zegami_roi
```

====================================

### Final steps after pipeline:
Note: outside conda environment:

###  1. Clustering:
#### Step i)  Create a single file containing all data. 

Merge all of the cellData.tab files from each ROI under analysis using the script mergecelldata.py

This file can also filter the data prior to merging using the --minarea and --maxarea arguments
```
python mergecelldata.py
```
- `--indir` initial directory level (default=signalextraction)
  
- `--excludeList` list of dirs to exclude as a pattern if you have bad samples
   - (for example e.g. --excludeList AA_SAMPLE_11_ROI_1 BB_SAMPLE_4_ROI_12)
  
- `--infile` name of the files to be merged (default=cellData.tab)
  
- `--outfile` merged output file (default=mergecellData.tab)
  
- `--minarea` minimum value for area of each cell (default=50)
  
- `--maxarea` maximum value for area of each cell (default=300)
  
#### Step ii)  Create a metadata file.

(optional) For the clustering step (see below), a metadata file describing all the samples contained in the aboved merged data file can be created using the script, make_metadata.py

```
python make_metadata.py
```
- `--indir` the location of files used to generate this metadata (default=deepcell)
 
- `--outfile` output file (default=metadata.tsv)


#### Step iii)  Clustering.
```
Rscript Rphenoclustering.R \
--panel_file <markers.tsv> \
--metadata_file <metadata.tsv> \
--analysisName <analysis_name> \
--datatransf scaledtrim
--k 15 \
--q 0.001 \
--run_dimRed TRUE \
--out_dir <path_to_out_dir> \
--save_sceobj
```
====================================

### 2. Spatial stats

\# [ not tested ] something like.....
```
python spatialstats.py -i StructuralIteration2.tab -o output -cl harmony_phenograph_exprs -c structural_iteration2.tab --roi HEALTHY_SAMPLE_1_ROI_1
```




